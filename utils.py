from torchvision import transforms
from PIL import Image, ImageFilter, ImageOps
import random
import torch
import math 
import warnings
import numpy as np
import matplotlib.pyplot as plt
import cv2

class ValidationAugmentation:
    def __init__(self):
        self.normalize = transforms.Compose([
        transforms.Resize(224),  # Resize shortest side to 224px
        transforms.CenterCrop(224),  # Take the center 224x224 region
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    def __call__(self, image):
        if isinstance(image, list):
            return [self.normalize(x.convert("RGB")) for x in image]
        else:
            # Ensure the image has 3 channels
            image = image.convert("RGB")
            return self.normalize(image)


def _no_grad_trunc_normal_(tensor, mean, std, a, b):
    # Cut & paste from PyTorch official master until it's in a few official releases - RW
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        warnings.warn("mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
                      "The distribution of values may be incorrect.",
                      stacklevel=2)

    with torch.no_grad():
        # Values are generated by using a truncated uniform distribution and
        # then using the inverse CDF for the normal distribution.
        # Get upper and lower cdf values
        l = norm_cdf((a - mean) / std)
        u = norm_cdf((b - mean) / std)

        # Uniformly fill tensor with values from [l, u], then translate to
        # [2l-1, 2u-1].
        tensor.uniform_(2 * l - 1, 2 * u - 1)

        # Use inverse cdf transform for normal distribution to get truncated
        # standard normal
        tensor.erfinv_()

        # Transform to proper mean, std
        tensor.mul_(std * math.sqrt(2.))
        tensor.add_(mean)

        # Clamp to ensure it's in the proper range
        tensor.clamp_(min=a, max=b)
        return tensor


def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):
    # type: (Tensor, float, float, float, float) -> Tensor
    return _no_grad_trunc_normal_(tensor, mean, std, a, b)

def reshape_attention_rollout(attention_rollout):
    # Shape (1, num_of_patches) (include CLS token)
    with torch.no_grad():
        attention_rollout = attention_rollout[0, 1:] # Exclude CLS token
        width = int(attention_rollout.size(-1)**0.5) # If image is 224x224, this will go form 196->14
        attention_rollout = attention_rollout.reshape(width, width).numpy()
        attention_rollout = attention_rollout /np.max(attention_rollout)
    return attention_rollout

def show_mask_on_image(img, mask):
    # Normalize image
    img = np.float32(img) / 255.0

    # Normalize and colorize mask
    heatmap = plt.cm.jet(mask)[:, :, :3]  # Apply color map and discard alpha channel if present
    heatmap = np.float32(heatmap)  # Ensure float format for combining
    cam = heatmap + img  # Overlay heatmap on image
    cam = cam / np.max(cam)  # Normalize the combined result

    return np.uint8(255 * cam)
    # if img.ndim == 3 and img.shape[-1] == 3:
    #     # Convert from BGR to RGB
    #     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # # If the image has an alpha channel (4th channel), discard it
    # if img.shape[-1] == 4:
    #     img = img[..., :3]

    # # Normalize base image to [0, 1]
    # img = np.float32(img) / 255.0

    # # Generate a heatmap using the standard "jet" colormap 
    # # (this reverses red/blue relative to "jet_r")
    # heatmap = plt.cm.jet(mask)[:, :, :3]  # discard alpha channel from colormap
    # heatmap = np.float32(heatmap)

    # # Overlay heatmap on the base image
    # cam = heatmap + img
    # # Avoid numeric blowup by normalizing to [0, 1]
    # cam = cam / np.max(cam)

    # # Convert back to 8-bit and return
    # return np.uint8(255 * cam)